#!/usr/bin/env python3
"""
å®Œå…¨æ¨¡æ‹ŸYOLOå®˜æ–¹é€Ÿåº¦æµ‹è¯•çš„è„šæœ¬
æµ‹è¯•å®Œæ•´æ¨¡å‹æ¨ç†ï¼ŒåŒ…æ‹¬åå¤„ç†ï¼Œä¸å®˜æ–¹æµ‹è¯•ä¿æŒä¸€è‡´
"""

import time
import torch
import numpy as np
import json
from datetime import datetime
import os
import sys

# æ·»åŠ è·¯å¾„
root_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(root_dir)

from my_ultralytics import YOLO
from my_ultralytics.utils import LOGGER
from my_ultralytics.utils.torch_utils import select_device

# ==================== é…ç½®å‚æ•° ====================
CONFIG = {
    # æ¨¡å‹é…ç½® - ä½¿ç”¨è®­ç»ƒå¥½çš„æƒé‡æ–‡ä»¶
    'model_path': '/mnt/zhouzj/mycode/runner/vit/notv10detect/weights/best.pt',
    
    # æµ‹è¯•é…ç½®
    'device': 'cuda',  # 'cpu', 'cuda', 'mps'
    'input_size': 640,  # è¾“å…¥å°ºå¯¸ï¼ˆYOLOæ ‡å‡†æ ¼å¼ï¼‰
    'batch_size': 1,    # æ‰¹æ¬¡å¤§å°
    'num_warmup': 10,   # é¢„çƒ­æ¬¡æ•°ï¼ˆä¸å®˜æ–¹ä¸€è‡´ï¼‰
    'num_runs': 100,    # æµ‹è¯•æ¬¡æ•°ï¼ˆä¸å®˜æ–¹ä¸€è‡´ï¼‰
    
    # å®˜æ–¹æµ‹è¯•é€‰é¡¹
    'half_precision': False,  # æ˜¯å¦ä½¿ç”¨FP16
    'include_nms': True,      # æ˜¯å¦åŒ…æ‹¬NMSåå¤„ç†
    'conf_threshold': 0.25,   # ç½®ä¿¡åº¦é˜ˆå€¼
    'iou_threshold': 0.45,    # NMS IoUé˜ˆå€¼
    'max_det': 300,           # æœ€å¤§æ£€æµ‹æ•°é‡
    
    # è¾“å‡ºé…ç½®
    'save_results': True,
    'results_dir': '/mnt/zhouzj/mycode/runner/speed',
    'verbose': True,
}

def create_dummy_input(imgsz, batch_size, device, half=False):
    """
    åˆ›å»ºä¸YOLOå®˜æ–¹æµ‹è¯•ä¸€è‡´çš„è™šæ‹Ÿè¾“å…¥
    """
    if isinstance(imgsz, int):
        imgsz = (imgsz, imgsz)
    
    # åˆ›å»ºæ ‡å‡†åŒ–çš„è¾“å…¥ï¼ˆ0-1èŒƒå›´ï¼ŒRGBæ ¼å¼ï¼‰
    dummy_input = torch.rand(batch_size, 3, imgsz[0], imgsz[1], device=device)
    
    if half:
        dummy_input = dummy_input.half()
    
    return dummy_input

def benchmark_official_style(model, imgsz, device, config):
    """
    å®Œå…¨æ¨¡æ‹ŸYOLOå®˜æ–¹çš„é€Ÿåº¦æµ‹è¯•æ–¹æ³•
    """
    print("ğŸ”¥ é¢„çƒ­é˜¶æ®µ...")
    
    # åˆ›å»ºè¾“å…¥
    dummy_input = create_dummy_input(imgsz, config['batch_size'], device, config['half_precision'])
    
    # é¢„çƒ­ - ä¸å®˜æ–¹ä¿æŒä¸€è‡´
    model.warmup(imgsz=(1 if config['batch_size'] == 1 else config['batch_size'], 3, imgsz, imgsz))
    
    # é¢å¤–é¢„çƒ­æ¨ç†
    with torch.no_grad():
        for _ in range(config['num_warmup']):
            if config['include_nms']:
                # å®Œæ•´æ¨ç†ï¼ˆåŒ…æ‹¬NMSï¼‰
                _ = model.predict(
                    dummy_input,
                    conf=config['conf_threshold'],
                    iou=config['iou_threshold'],
                    max_det=config['max_det'],
                    verbose=False,
                    save=False,
                    show=False,
                )
            else:
                # ä»…å‰å‘ä¼ æ’­
                _ = model.model(dummy_input)
    
    # åŒæ­¥GPU
    if device.type == 'cuda':
        torch.cuda.synchronize()
    
    print("â±ï¸  å¼€å§‹å®˜æ–¹é£æ ¼é€Ÿåº¦æµ‹è¯•...")
    
    # æµ‹è¯•é˜¶æ®µ
    times = []
    
    with torch.no_grad():
        for i in range(config['num_runs']):
            # GPUç²¾ç¡®è®¡æ—¶
            if device.type == 'cuda':
                start_event = torch.cuda.Event(enable_timing=True)
                end_event = torch.cuda.Event(enable_timing=True)
                
                start_event.record()
                
                if config['include_nms']:
                    # å®Œæ•´æ¨ç†ï¼ˆè¿™æ˜¯å®˜æ–¹æµ‹è¯•çš„æ–¹å¼ï¼‰
                    results = model.predict(
                        dummy_input,
                        conf=config['conf_threshold'],
                        iou=config['iou_threshold'],
                        max_det=config['max_det'],
                        verbose=False,
                        save=False,
                        show=False,
                    )
                else:
                    # ä»…å‰å‘ä¼ æ’­
                    _ = model.model(dummy_input)
                
                end_event.record()
                torch.cuda.synchronize()
                
                elapsed_time = start_event.elapsed_time(end_event)  # æ¯«ç§’
                
            else:
                # CPUè®¡æ—¶
                start_time = time.perf_counter()
                
                if config['include_nms']:
                    results = model.predict(
                        dummy_input,
                        conf=config['conf_threshold'],
                        iou=config['iou_threshold'],
                        max_det=config['max_det'],
                        verbose=False,
                        save=False,
                        show=False,
                    )
                else:
                    _ = model.model(dummy_input)
                
                end_time = time.perf_counter()
                elapsed_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            times.append(elapsed_time)
            
            # æ˜¾ç¤ºè¿›åº¦
            if config['verbose'] and (i + 1) % 20 == 0:
                current_avg = np.mean(times)
                print(f"   è¿›åº¦: {i + 1}/{config['num_runs']}, å½“å‰å¹³å‡: {current_avg:.2f}ms")
    
    return np.array(times)

def test_official_speed(config):
    """
    å®˜æ–¹é£æ ¼çš„å®Œæ•´é€Ÿåº¦æµ‹è¯•
    """
    print("="*60)
    print("ğŸš€ YOLOå®˜æ–¹é£æ ¼é€Ÿåº¦æµ‹è¯•")
    print("="*60)
    print(f"æ¨¡å‹è·¯å¾„: {config['model_path']}")
    print(f"è®¾å¤‡: {config['device']}")
    print(f"è¾“å…¥å°ºå¯¸: {config['input_size']}")
    print(f"æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
    print(f"åŠç²¾åº¦: {config['half_precision']}")
    print(f"åŒ…å«NMS: {config['include_nms']}")
    print(f"ç½®ä¿¡åº¦é˜ˆå€¼: {config['conf_threshold']}")
    print(f"IoUé˜ˆå€¼: {config['iou_threshold']}")
    print("-"*60)
    
    # é€‰æ‹©è®¾å¤‡ï¼ˆä½¿ç”¨YOLOå®˜æ–¹æ–¹æ³•ï¼‰
    device = select_device(config['device'])
    print(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨YOLOå®˜æ–¹æ–¹æ³•ï¼‰
    print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
    try:
        model = YOLO(config['model_path'])
        model.to(device)
        
        # è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼
        model.model.eval()
        
        # åŠç²¾åº¦è®¾ç½®
        if config['half_precision'] and device.type == 'cuda':
            model.model.half()
            print("ğŸš€ å¯ç”¨FP16åŠç²¾åº¦")
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        if hasattr(model.model, 'model'):
            total_params = sum(p.numel() for p in model.model.parameters())
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {total_params:,}")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    imgsz = config['input_size']
    times = benchmark_official_style(model, imgsz, device, config)
    
    if len(times) == 0:
        print("âŒ æµ‹è¯•å¤±è´¥")
        return None
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'successful_runs': len(times),
        'total_runs': config['num_runs'],
        'mean_time': float(np.mean(times)),
        'std_time': float(np.std(times)),
        'min_time': float(np.min(times)),
        'max_time': float(np.max(times)),
        'median_time': float(np.median(times)),
        'p95_time': float(np.percentile(times, 95)),
        'p99_time': float(np.percentile(times, 99)),
        'p1_time': float(np.percentile(times, 1)),
    }
    
    # è®¡ç®—FPSå’Œååé‡
    batch_size = config['batch_size']
    stats['fps'] = 1000 / stats['mean_time'] * batch_size
    stats['throughput'] = stats['fps']
    
    # è¾“å‡ºç»“æœï¼ˆå®˜æ–¹é£æ ¼ï¼‰
    print("\n" + "="*60)
    print("ğŸ“Š YOLOå®˜æ–¹é£æ ¼é€Ÿåº¦æµ‹è¯•ç»“æœ")
    print("="*60)
    print(f"âœ… æˆåŠŸè¿è¡Œ: {len(times)}/{config['num_runs']} æ¬¡")
    print(f"ğŸ“ˆ å¹³å‡æ¨ç†æ—¶é—´: {stats['mean_time']:.2f}ms")
    print(f"ğŸ“Š ä¸­ä½æ•°æ—¶é—´: {stats['median_time']:.2f}ms") 
    print(f"âš¡ æœ€å¿«æ¨ç†æ—¶é—´: {stats['min_time']:.2f}ms")
    print(f"ğŸŒ æœ€æ…¢æ¨ç†æ—¶é—´: {stats['max_time']:.2f}ms")
    print(f"ğŸš€ å¹³å‡FPS: {stats['fps']:.1f}")
    print(f"ğŸ”¥ å³°å€¼FPS: {1000/stats['min_time']:.1f}")
    
    # å®˜æ–¹é£æ ¼çš„æ€§èƒ½æ‘˜è¦
    print(f"\nğŸ“‹ æ€§èƒ½æ‘˜è¦:")
    print(f"   æ¨ç†é€Ÿåº¦: {stats['mean_time']:.2f}ms Â± {stats['std_time']:.2f}ms")
    print(f"   FPS: {stats['fps']:.1f}")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   è¾“å…¥å°ºå¯¸: {config['input_size']}x{config['input_size']}")
    print(f"   ç²¾åº¦: {'FP16' if config['half_precision'] else 'FP32'}")
    print(f"   åŒ…å«åå¤„ç†: {'æ˜¯' if config['include_nms'] else 'å¦'}")
    
    # ä¸å®˜æ–¹åŸºå‡†å¯¹æ¯”æç¤º
    print(f"\nğŸ’¡ ä¸å®˜æ–¹åŸºå‡†å¯¹æ¯”:")
    print(f"   YOLOv8n (640): ~1.0ms (A100), ~10ms (V100), ~50ms (CPU)")
    print(f"   YOLOv8s (640): ~1.2ms (A100), ~12ms (V100), ~60ms (CPU)")
    print(f"   YOLOv8m (640): ~2.0ms (A100), ~20ms (V100), ~95ms (CPU)")
    print(f"   ä½ çš„ç»“æœ: {stats['mean_time']:.2f}ms ({device.type.upper()})")
    
    # ä¿å­˜ç»“æœ
    if config['save_results']:
        save_results(config, stats, times, device)
    
    return stats

def save_results(config, stats, times, device):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    try:
        os.makedirs(config['results_dir'], exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"official_speed_test_{timestamp}.json"
        filepath = os.path.join(config['results_dir'], filename)
        
        data = {
            'timestamp': timestamp,
            'config': config,
            'statistics': stats,
            'all_times': times.tolist(),
            'device_info': {
                'device': str(device),
                'torch_version': torch.__version__,
                'cuda_available': torch.cuda.is_available(),
                'cuda_version': torch.version.cuda if torch.cuda.is_available() else None,
                'gpu_name': torch.cuda.get_device_name() if torch.cuda.is_available() else None,
                'gpu_memory': torch.cuda.get_device_properties(device).total_memory if device.type == 'cuda' else None,
            }
        }
        
        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2)
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {filepath}")
        
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜å¤±è´¥: {e}")

def main():
    print("ğŸš€ å¼€å§‹YOLOå®˜æ–¹é£æ ¼é€Ÿåº¦æµ‹è¯•")
    print(f"â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ˜¾ç¤ºé…ç½®
    print("\nğŸ“‹ æµ‹è¯•é…ç½®:")
    for key, value in CONFIG.items():
        if key != 'model_path' or len(str(value)) < 50:
            print(f"   {key}: {value}")
        else:
            print(f"   {key}: ...{str(value)[-30:]}")
    
    print("-" * 60)
    
    # è¿è¡Œæµ‹è¯•
    results = test_official_speed(CONFIG)
    
    if results:
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")
        print(f"ğŸ”¥ å¹³å‡æ¨ç†æ—¶é—´: {results['mean_time']:.2f}ms")
        print(f"ğŸš€ å¹³å‡FPS: {results['fps']:.1f}")
        print(f"âš¡ å³°å€¼FPS: {1000/results['min_time']:.1f}")
        
        # æ€§èƒ½ç­‰çº§è¯„ä¼°
        avg_time = results['mean_time']
        if avg_time < 5:
            print("ğŸ† æ€§èƒ½ç­‰çº§: ä¼˜ç§€ (< 5ms)")
        elif avg_time < 15:
            print("ğŸ¥ˆ æ€§èƒ½ç­‰çº§: è‰¯å¥½ (< 15ms)")
        elif avg_time < 50:
            print("ğŸ¥‰ æ€§èƒ½ç­‰çº§: ä¸€èˆ¬ (< 50ms)")
        else:
            print("âš ï¸  æ€§èƒ½ç­‰çº§: éœ€è¦ä¼˜åŒ– (â‰¥ 50ms)")
    else:
        print("\nğŸ’¥ æµ‹è¯•å¤±è´¥!")

if __name__ == "__main__":
    main()